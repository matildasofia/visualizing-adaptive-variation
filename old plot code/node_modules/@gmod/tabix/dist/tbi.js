"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const long_1 = __importDefault(require("long"));
const virtualOffset_1 = __importStar(require("./virtualOffset"));
const chunk_1 = __importDefault(require("./chunk"));
const bgzf_filehandle_1 = require("@gmod/bgzf-filehandle");
const util_1 = require("./util");
const indexFile_1 = __importDefault(require("./indexFile"));
const TBI_MAGIC = 21578324; // TBI\1
const TAD_LIDX_SHIFT = 14;
/**
 * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)
 */
function reg2bins(beg, end) {
    beg += 1; // < convert to 1-based closed
    end -= 1;
    return [
        [0, 0],
        [1 + (beg >> 26), 1 + (end >> 26)],
        [9 + (beg >> 23), 9 + (end >> 23)],
        [73 + (beg >> 20), 73 + (end >> 20)],
        [585 + (beg >> 17), 585 + (end >> 17)],
        [4681 + (beg >> 14), 4681 + (end >> 14)],
    ];
}
class TabixIndex extends indexFile_1.default {
    lineCount(refName, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const indexData = yield this.parse(opts);
            if (!indexData) {
                return -1;
            }
            const refId = indexData.refNameToId[refName];
            const idx = indexData.indices[refId];
            if (!idx) {
                return -1;
            }
            const { stats } = indexData.indices[refId];
            if (stats) {
                return stats.lineCount;
            }
            return -1;
        });
    }
    // fetch and parse the index
    _parse(opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const buf = yield this.filehandle.readFile(opts);
            const bytes = yield (0, bgzf_filehandle_1.unzip)(buf);
            (0, util_1.checkAbortSignal)(opts.signal);
            // check TBI magic numbers
            if (bytes.readUInt32LE(0) !== TBI_MAGIC /* "TBI\1" */) {
                throw new Error('Not a TBI file');
                // TODO: do we need to support big-endian TBI files?
            }
            // number of reference sequences in the index
            const refCount = bytes.readInt32LE(4);
            const formatFlags = bytes.readInt32LE(8);
            const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';
            const formatOpts = {
                0: 'generic',
                1: 'SAM',
                2: 'VCF',
            };
            const format = formatOpts[formatFlags & 0xf];
            if (!format) {
                throw new Error(`invalid Tabix preset format flags ${formatFlags}`);
            }
            const columnNumbers = {
                ref: bytes.readInt32LE(12),
                start: bytes.readInt32LE(16),
                end: bytes.readInt32LE(20),
            };
            const metaValue = bytes.readInt32LE(24);
            const depth = 5;
            const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7;
            const maxRefLength = Math.pow(2, (14 + depth * 3));
            const metaChar = metaValue ? String.fromCharCode(metaValue) : null;
            const skipLines = bytes.readInt32LE(28);
            // read sequence dictionary
            const nameSectionLength = bytes.readInt32LE(32);
            const { refNameToId, refIdToName } = this._parseNameBytes(bytes.slice(36, 36 + nameSectionLength));
            // read the indexes for each reference sequence
            let currOffset = 36 + nameSectionLength;
            let firstDataLine;
            const indices = new Array(refCount).fill(0).map(() => {
                // the binning index
                const binCount = bytes.readInt32LE(currOffset);
                currOffset += 4;
                const binIndex = {};
                let stats;
                for (let j = 0; j < binCount; j += 1) {
                    const bin = bytes.readUInt32LE(currOffset);
                    currOffset += 4;
                    if (bin > maxBinNumber + 1) {
                        throw new Error('tabix index contains too many bins, please use a CSI index');
                    }
                    else if (bin === maxBinNumber + 1) {
                        const chunkCount = bytes.readInt32LE(currOffset);
                        currOffset += 4;
                        if (chunkCount === 2) {
                            stats = this.parsePseudoBin(bytes, currOffset);
                        }
                        currOffset += 16 * chunkCount;
                    }
                    else {
                        const chunkCount = bytes.readInt32LE(currOffset);
                        currOffset += 4;
                        const chunks = new Array(chunkCount);
                        for (let k = 0; k < chunkCount; k += 1) {
                            const u = (0, virtualOffset_1.fromBytes)(bytes, currOffset);
                            const v = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 8);
                            currOffset += 16;
                            firstDataLine = this._findFirstData(firstDataLine, u);
                            chunks[k] = new chunk_1.default(u, v, bin);
                        }
                        binIndex[bin] = chunks;
                    }
                }
                // the linear index
                const linearCount = bytes.readInt32LE(currOffset);
                currOffset += 4;
                const linearIndex = new Array(linearCount);
                for (let k = 0; k < linearCount; k += 1) {
                    linearIndex[k] = (0, virtualOffset_1.fromBytes)(bytes, currOffset);
                    currOffset += 8;
                    firstDataLine = this._findFirstData(firstDataLine, linearIndex[k]);
                }
                return { binIndex, linearIndex, stats };
            });
            return {
                indices,
                metaChar,
                maxBinNumber,
                maxRefLength,
                skipLines,
                firstDataLine,
                columnNumbers,
                coordinateType,
                format,
                refIdToName,
                refNameToId,
                maxBlockSize: 1 << 16,
            };
        });
    }
    parsePseudoBin(bytes, offset) {
        const lineCount = (0, util_1.longToNumber)(long_1.default.fromBytesLE(bytes.slice(offset + 16, offset + 24), true));
        return { lineCount };
    }
    _parseNameBytes(namesBytes) {
        let currRefId = 0;
        let currNameStart = 0;
        const refIdToName = [];
        const refNameToId = {};
        for (let i = 0; i < namesBytes.length; i += 1) {
            if (!namesBytes[i]) {
                if (currNameStart < i) {
                    let refName = namesBytes.toString('utf8', currNameStart, i);
                    refName = this.renameRefSeq(refName);
                    refIdToName[currRefId] = refName;
                    refNameToId[refName] = currRefId;
                }
                currNameStart = i + 1;
                currRefId += 1;
            }
        }
        return { refNameToId, refIdToName };
    }
    blocksForRange(refName, min, max, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            if (min < 0) {
                min = 0;
            }
            const indexData = yield this.parse(opts);
            if (!indexData) {
                return [];
            }
            const refId = indexData.refNameToId[refName];
            const ba = indexData.indices[refId];
            if (!ba) {
                return [];
            }
            const minOffset = ba.linearIndex.length
                ? ba.linearIndex[min >> TAD_LIDX_SHIFT >= ba.linearIndex.length
                    ? ba.linearIndex.length - 1
                    : min >> TAD_LIDX_SHIFT]
                : new virtualOffset_1.default(0, 0);
            if (!minOffset) {
                console.warn('querying outside of possible tabix range');
            }
            // const { linearIndex, binIndex } = indexes
            const overlappingBins = reg2bins(min, max); // List of bin #s that overlap min, max
            const chunks = [];
            // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned
            for (const [start, end] of overlappingBins) {
                for (let bin = start; bin <= end; bin++) {
                    if (ba.binIndex[bin]) {
                        const binChunks = ba.binIndex[bin];
                        for (let c = 0; c < binChunks.length; ++c) {
                            chunks.push(new chunk_1.default(binChunks[c].minv, binChunks[c].maxv, bin));
                        }
                    }
                }
            }
            // Use the linear index to find minimum file position of chunks that could
            // contain alignments in the region
            const nintv = ba.linearIndex.length;
            let lowest = null;
            const minLin = Math.min(min >> 14, nintv - 1);
            const maxLin = Math.min(max >> 14, nintv - 1);
            for (let i = minLin; i <= maxLin; ++i) {
                const vp = ba.linearIndex[i];
                if (vp) {
                    if (!lowest || vp.compareTo(lowest) < 0) {
                        lowest = vp;
                    }
                }
            }
            return (0, util_1.optimizeChunks)(chunks, lowest);
        });
    }
}
exports.default = TabixIndex;
//# sourceMappingURL=tbi.js.map