"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const abortable_promise_cache_1 = __importDefault(require("abortable-promise-cache"));
const quick_lru_1 = __importDefault(require("quick-lru"));
const buffer_1 = require("buffer");
const generic_filehandle_1 = require("generic-filehandle");
const bgzf_filehandle_1 = require("@gmod/bgzf-filehandle");
const util_1 = require("./util");
const tbi_1 = __importDefault(require("./tbi"));
const csi_1 = __importDefault(require("./csi"));
const decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder('utf-8') : undefined;
function timeout(time) {
    return new Promise(resolve => setTimeout(resolve, time));
}
class TabixIndexedFile {
    /**
     * @param {object} args
     * @param {string} [args.path]
     * @param {filehandle} [args.filehandle]
     * @param {string} [args.tbiPath]
     * @param {filehandle} [args.tbiFilehandle]
     * @param {string} [args.csiPath]
     * @param {filehandle} [args.csiFilehandle]
     * @param {number} [args.yieldTime] yield to main thread after N milliseconds if reading features is taking a long time to avoid hanging main thread
     * @param {function} [args.renameRefSeqs] optional function with sig `string => string` to transform
     * reference sequence names for the purpose of indexing and querying. note that the data that is returned is
     * not altered, just the names of the reference sequences that are used for querying.
     */
    constructor({ path, filehandle, tbiPath, tbiFilehandle, csiPath, csiFilehandle, yieldTime = 500, chunkSizeLimit = 50000000, renameRefSeqs = n => n, chunkCacheSize = 5 * Math.pow(2, 20), }) {
        if (filehandle) {
            this.filehandle = filehandle;
        }
        else if (path) {
            this.filehandle = new generic_filehandle_1.LocalFile(path);
        }
        else {
            throw new TypeError('must provide either filehandle or path');
        }
        if (tbiFilehandle) {
            this.index = new tbi_1.default({
                filehandle: tbiFilehandle,
                renameRefSeqs,
            });
        }
        else if (csiFilehandle) {
            this.index = new csi_1.default({
                filehandle: csiFilehandle,
                renameRefSeqs,
            });
        }
        else if (tbiPath) {
            this.index = new tbi_1.default({
                filehandle: new generic_filehandle_1.LocalFile(tbiPath),
                renameRefSeqs,
            });
        }
        else if (csiPath) {
            this.index = new csi_1.default({
                filehandle: new generic_filehandle_1.LocalFile(csiPath),
                renameRefSeqs,
            });
        }
        else if (path) {
            this.index = new tbi_1.default({
                filehandle: new generic_filehandle_1.LocalFile(`${path}.tbi`),
                renameRefSeqs,
            });
        }
        else {
            throw new TypeError('must provide one of tbiFilehandle, tbiPath, csiFilehandle, or csiPath');
        }
        this.chunkSizeLimit = chunkSizeLimit;
        this.renameRefSeq = renameRefSeqs;
        this.yieldTime = yieldTime;
        this.chunkCache = new abortable_promise_cache_1.default({
            cache: new quick_lru_1.default({ maxSize: Math.floor(chunkCacheSize / (1 << 16)) }),
            fill: (args, signal) => this.readChunk(args, { signal }),
        });
    }
    /**
     * @param refName name of the reference sequence
     * @param start start of the region (in 0-based half-open coordinates)
     * @param end end of the region (in 0-based half-open coordinates)
     * @param opts callback called for each line in the region. can also pass a object param containing obj.lineCallback, obj.signal, etc
     * @returns promise that is resolved when the whole read is finished, rejected on error
     */
    getLines(refName, start, end, opts) {
        return __awaiter(this, void 0, void 0, function* () {
            let signal;
            let options = {};
            let callback;
            if (typeof opts === 'undefined') {
                throw new TypeError('line callback must be provided');
            }
            if (typeof opts === 'function') {
                callback = opts;
            }
            else {
                options = opts;
                callback = opts.lineCallback;
            }
            if (refName === undefined) {
                throw new TypeError('must provide a reference sequence name');
            }
            if (!callback) {
                throw new TypeError('line callback must be provided');
            }
            const metadata = yield this.index.getMetadata(options);
            (0, util_1.checkAbortSignal)(signal);
            if (!start) {
                start = 0;
            }
            if (!end) {
                end = metadata.maxRefLength;
            }
            if (!(start <= end)) {
                throw new TypeError('invalid start and end coordinates. start must be less than or equal to end');
            }
            if (start === end) {
                return;
            }
            const chunks = yield this.index.blocksForRange(refName, start, end, options);
            (0, util_1.checkAbortSignal)(signal);
            // check the chunks for any that are over the size limit.  if
            // any are, don't fetch any of them
            for (let i = 0; i < chunks.length; i += 1) {
                const size = chunks[i].fetchedSize();
                if (size > this.chunkSizeLimit) {
                    throw new Error(`Too much data. Chunk size ${size.toLocaleString()} bytes exceeds chunkSizeLimit of ${this.chunkSizeLimit.toLocaleString()}.`);
                }
            }
            // now go through each chunk and parse and filter the lines out of it
            let last = Date.now();
            for (let chunkNum = 0; chunkNum < chunks.length; chunkNum += 1) {
                let previousStartCoordinate;
                const c = chunks[chunkNum];
                const { buffer, cpositions, dpositions } = yield this.chunkCache.get(c.toString(), c);
                (0, util_1.checkAbortSignal)(signal);
                let blockStart = 0;
                let pos = 0;
                while (blockStart < buffer.length) {
                    const n = buffer.indexOf('\n', blockStart);
                    if (n === -1) {
                        break;
                    }
                    const b = buffer.slice(blockStart, n);
                    const line = (decoder === null || decoder === void 0 ? void 0 : decoder.decode(b)) || b.toString();
                    if (dpositions) {
                        while (blockStart + c.minv.dataPosition >= dpositions[pos++]) { }
                        pos--;
                    }
                    // filter the line for whether it is within the requested range
                    const { startCoordinate, overlaps } = this.checkLine(metadata, refName, start, end, line);
                    // do a small check just to make sure that the lines are really sorted
                    // by start coordinate
                    if (previousStartCoordinate !== undefined &&
                        startCoordinate !== undefined &&
                        previousStartCoordinate > startCoordinate) {
                        throw new Error(`Lines not sorted by start coordinate (${previousStartCoordinate} > ${startCoordinate}), this file is not usable with Tabix.`);
                    }
                    previousStartCoordinate = startCoordinate;
                    if (overlaps) {
                        callback(line.trim(), 
                        // cpositions[pos] refers to actual file offset of a bgzip block boundaries
                        //
                        // we multiply by (1 <<8) in order to make sure each block has a "unique"
                        // address space so that data in that block could never overlap
                        //
                        // then the blockStart-dpositions is an uncompressed file offset from
                        // that bgzip block boundary, and since the cpositions are multiplied by
                        // (1 << 8) these uncompressed offsets get a unique space
                        cpositions[pos] * (1 << 8) +
                            (blockStart - dpositions[pos]) +
                            c.minv.dataPosition +
                            1);
                    }
                    else if (startCoordinate !== undefined && startCoordinate >= end) {
                        // the lines were overlapping the region, but now have stopped, so
                        // we must be at the end of the relevant data and we can stop
                        // processing data now
                        return;
                    }
                    // yield if we have emitted beyond the yield limit
                    if (this.yieldTime && last - Date.now() > this.yieldTime) {
                        last = Date.now();
                        (0, util_1.checkAbortSignal)(signal);
                        yield timeout(1);
                    }
                    blockStart = n + 1;
                }
            }
        });
    }
    getMetadata(opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.index.getMetadata(opts);
        });
    }
    /**
     * get a buffer containing the "header" region of
     * the file, which are the bytes up to the first
     * non-meta line
     */
    getHeaderBuffer(opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const { firstDataLine, metaChar, maxBlockSize } = yield this.getMetadata(opts);
            (0, util_1.checkAbortSignal)(opts.signal);
            const maxFetch = ((firstDataLine === null || firstDataLine === void 0 ? void 0 : firstDataLine.blockPosition) || 0) + maxBlockSize;
            // TODO: what if we don't have a firstDataLine, and the header
            // actually takes up more than one block? this case is not covered here
            let bytes = yield this._readRegion(0, maxFetch, opts);
            (0, util_1.checkAbortSignal)(opts.signal);
            try {
                bytes = yield (0, bgzf_filehandle_1.unzip)(bytes);
            }
            catch (e) {
                console.error(e);
                throw new Error(
                //@ts-ignore
                `error decompressing block ${e.code} at 0 (length ${maxFetch}) ${e}`);
            }
            // trim off lines after the last non-meta line
            if (metaChar) {
                // trim backward from the end
                let lastNewline = -1;
                const newlineByte = '\n'.charCodeAt(0);
                const metaByte = metaChar.charCodeAt(0);
                for (let i = 0; i < bytes.length; i += 1) {
                    if (i === lastNewline + 1 && bytes[i] !== metaByte) {
                        break;
                    }
                    if (bytes[i] === newlineByte) {
                        lastNewline = i;
                    }
                }
                bytes = bytes.slice(0, lastNewline + 1);
            }
            return bytes;
        });
    }
    /**
     * get a string containing the "header" region of the
     * file, is the portion up to the first non-meta line
     *
     * @returns {Promise} for a string
     */
    getHeader(opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const bytes = yield this.getHeaderBuffer(opts);
            return bytes.toString('utf8');
        });
    }
    /**
     * get an array of reference sequence names, in the order in which
     * they occur in the file. reference sequence renaming is not applied
     * to these names.
     */
    getReferenceSequenceNames(opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const metadata = yield this.getMetadata(opts);
            return metadata.refIdToName;
        });
    }
    /**
     * @param {object} metadata metadata object from the parsed index,
     * containing columnNumbers, metaChar, and format
     * @param {string} regionRefName
     * @param {number} regionStart region start coordinate (0-based-half-open)
     * @param {number} regionEnd region end coordinate (0-based-half-open)
     * @param {array[string]} line
     * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,
     * true if line is a data line that overlaps the given region
     */
    checkLine(metadata, regionRefName, regionStart, regionEnd, line) {
        const { columnNumbers, metaChar, coordinateType, format } = metadata;
        // skip meta lines
        if (line.charAt(0) === metaChar) {
            return { overlaps: false };
        }
        // check ref/start/end using column metadata from index
        let { ref, start, end } = columnNumbers;
        if (!ref) {
            ref = 0;
        }
        if (!start) {
            start = 0;
        }
        if (!end) {
            end = 0;
        }
        if (format === 'VCF') {
            end = 8;
        }
        const maxColumn = Math.max(ref, start, end);
        // this code is kind of complex, but it is fairly fast.
        // basically, we want to avoid doing a split, because if the lines are really long
        // that could lead to us allocating a bunch of extra memory, which is slow
        let currentColumnNumber = 1; // cols are numbered starting at 1 in the index metadata
        let currentColumnStart = 0;
        let refSeq = '';
        let startCoordinate = -Infinity;
        for (let i = 0; i < line.length + 1; i += 1) {
            if (line[i] === '\t' || i === line.length) {
                if (currentColumnNumber === ref) {
                    if (this.renameRefSeq(line.slice(currentColumnStart, i)) !==
                        regionRefName) {
                        return { overlaps: false };
                    }
                }
                else if (currentColumnNumber === start) {
                    startCoordinate = parseInt(line.slice(currentColumnStart, i), 10);
                    // we convert to 0-based-half-open
                    if (coordinateType === '1-based-closed') {
                        startCoordinate -= 1;
                    }
                    if (startCoordinate >= regionEnd) {
                        return { startCoordinate, overlaps: false };
                    }
                    if (end === 0 || end === start) {
                        // if we have no end, we assume the feature is 1 bp long
                        if (startCoordinate + 1 <= regionStart) {
                            return { startCoordinate, overlaps: false };
                        }
                    }
                }
                else if (format === 'VCF' && currentColumnNumber === 4) {
                    refSeq = line.slice(currentColumnStart, i);
                }
                else if (currentColumnNumber === end) {
                    let endCoordinate;
                    // this will never match if there is no end column
                    if (format === 'VCF') {
                        endCoordinate = this._getVcfEnd(startCoordinate, refSeq, line.slice(currentColumnStart, i));
                    }
                    else {
                        endCoordinate = parseInt(line.slice(currentColumnStart, i), 10);
                    }
                    if (endCoordinate <= regionStart) {
                        return { overlaps: false };
                    }
                }
                currentColumnStart = i + 1;
                currentColumnNumber += 1;
                if (currentColumnNumber > maxColumn) {
                    break;
                }
            }
        }
        return { startCoordinate, overlaps: true };
    }
    _getVcfEnd(startCoordinate, refSeq, info) {
        let endCoordinate = startCoordinate + refSeq.length;
        // ignore TRA features as they specify CHR2 and END
        // as being on a different chromosome
        // if CHR2 is on the same chromosome, still ignore it
        // because there should be another pairwise feature
        // at the end of this one
        const isTRA = info.indexOf('SVTYPE=TRA') !== -1;
        if (info[0] !== '.' && !isTRA) {
            let prevChar = ';';
            for (let j = 0; j < info.length; j += 1) {
                if (prevChar === ';' && info.slice(j, j + 4) === 'END=') {
                    let valueEnd = info.indexOf(';', j);
                    if (valueEnd === -1) {
                        valueEnd = info.length;
                    }
                    endCoordinate = parseInt(info.slice(j + 4, valueEnd), 10);
                    break;
                }
                prevChar = info[j];
            }
        }
        else if (isTRA) {
            return startCoordinate + 1;
        }
        return endCoordinate;
    }
    /**
     * return the approximate number of data lines in the given reference sequence
     * @param refSeq reference sequence name
     * @returns number of data lines present on that reference sequence
     */
    lineCount(refName, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.index.lineCount(refName, opts);
        });
    }
    _readRegion(pos, size, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const b = buffer_1.Buffer.alloc(size);
            const { bytesRead, buffer } = yield this.filehandle.read(b, 0, size, pos, opts);
            return buffer.slice(0, bytesRead);
        });
    }
    /**
     * read and uncompress the data in a chunk (composed of one or more
     * contiguous bgzip blocks) of the file
     */
    readChunk(c, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            // fetch the uncompressed data, uncompress carefully a block at a time,
            // and stop when done
            const data = yield this._readRegion(c.minv.blockPosition, c.fetchedSize(), opts);
            try {
                return (0, bgzf_filehandle_1.unzipChunkSlice)(data, c);
            }
            catch (e) {
                throw new Error(`error decompressing c ${c.toString()} ${e}`);
            }
        });
    }
}
exports.default = TabixIndexedFile;
//# sourceMappingURL=tabixIndexedFile.js.map