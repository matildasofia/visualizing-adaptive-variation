"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.BigBed = exports.filterUndef = void 0;
const buffer_1 = require("buffer");
const binary_parser_1 = require("binary-parser");
const rxjs_1 = require("rxjs");
const operators_1 = require("rxjs/operators");
const abortable_promise_cache_1 = __importDefault(require("abortable-promise-cache"));
const quick_lru_1 = __importDefault(require("quick-lru"));
const bbi_1 = require("./bbi");
function filterUndef(ts) {
    return ts.filter((t) => !!t);
}
exports.filterUndef = filterUndef;
class BigBed extends bbi_1.BBI {
    constructor() {
        super(...arguments);
        this.readIndicesCache = new abortable_promise_cache_1.default({
            cache: new quick_lru_1.default({ maxSize: 1 }),
            fill: (args, signal) => __awaiter(this, void 0, void 0, function* () {
                return this._readIndices(Object.assign(Object.assign({}, args), { signal }));
            }),
        });
    }
    readIndices(opts = {}) {
        const options = 'aborted' in opts ? { signal: opts } : opts;
        return this.readIndicesCache.get(JSON.stringify(options), options, options.signal);
    }
    /*
     * retrieve unzoomed view for any scale
     * @param scale - unused
     * @param abortSignal - an optional AbortSignal to kill operation
     * @return promise for a BlockView
     */
    getView(_scale, opts) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.getUnzoomedView(opts);
        });
    }
    /*
     * parse the bigbed extraIndex fields
     * @param abortSignal to abort operation
     * @return a Promise for an array of Index data structure since there can be multiple extraIndexes in a bigbed, see bedToBigBed documentation
     */
    _readIndices(opts) {
        return __awaiter(this, void 0, void 0, function* () {
            const { extHeaderOffset, isBigEndian } = yield this.getHeader(opts);
            const { buffer: data } = yield this.bbi.read(buffer_1.Buffer.alloc(64), 0, 64, Number(extHeaderOffset));
            const le = isBigEndian ? 'big' : 'little';
            const ret = new binary_parser_1.Parser()
                .endianess(le)
                .uint16('size')
                .uint16('count')
                .uint64('offset')
                .parse(data);
            const { count, offset } = ret;
            // no extra index is defined if count==0
            if (count === 0) {
                return [];
            }
            const blocklen = 20;
            const len = blocklen * count;
            const { buffer } = yield this.bbi.read(buffer_1.Buffer.alloc(len), 0, len, Number(offset));
            const extParser = new binary_parser_1.Parser()
                .endianess(le)
                .int16('type')
                .int16('fieldcount')
                .uint64('offset')
                .skip(4)
                .int16('field');
            const indices = [];
            for (let i = 0; i < count; i += 1) {
                indices.push(extParser.parse(buffer.subarray(i * blocklen)));
            }
            return indices;
        });
    }
    /*
     * perform a search in the bigbed extraIndex to find which blocks in the bigbed data to look for the
     * actual feature data
     *
     * @param name - the name to search for
     * @param opts - a SearchOptions argument with optional signal
     * @return a Promise for an array of bigbed block Loc entries
     */
    searchExtraIndexBlocks(name, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const { isBigEndian } = yield this.getHeader(opts);
            const indices = yield this.readIndices(opts);
            if (!indices.length) {
                return [];
            }
            const locs = indices.map((index) => __awaiter(this, void 0, void 0, function* () {
                const { offset, field } = index;
                const { buffer: data } = yield this.bbi.read(buffer_1.Buffer.alloc(32), 0, 32, Number(offset), opts);
                const le = isBigEndian ? 'big' : 'little';
                const p = new binary_parser_1.Parser()
                    .endianess(le)
                    .int32('magic')
                    .int32('blockSize')
                    .int32('keySize')
                    .int32('valSize')
                    .uint64('itemCount');
                const { blockSize, keySize, valSize } = p.parse(data);
                // console.log({blockSize,keySize,valSize})
                const bpt = new binary_parser_1.Parser()
                    .endianess(le)
                    .int8('nodeType')
                    .skip(1)
                    .int16('cnt')
                    .choice({
                    tag: 'nodeType',
                    choices: {
                        0: new binary_parser_1.Parser().array('leafkeys', {
                            length: 'cnt',
                            type: new binary_parser_1.Parser()
                                .endianess(le)
                                .string('key', { length: keySize, stripNull: true })
                                .uint64('offset'),
                        }),
                        1: new binary_parser_1.Parser().array('keys', {
                            length: 'cnt',
                            type: new binary_parser_1.Parser()
                                .endianess(le)
                                .string('key', { length: keySize, stripNull: true })
                                .uint64('offset')
                                .uint32('length')
                                .uint32('reserved'),
                        }),
                    },
                });
                const bptReadNode = (nodeOffset) => __awaiter(this, void 0, void 0, function* () {
                    const val = Number(nodeOffset);
                    const len = 4 + blockSize * (keySize + valSize);
                    const { buffer } = yield this.bbi.read(buffer_1.Buffer.alloc(len), 0, len, val, opts);
                    const node = bpt.parse(buffer);
                    if (node.leafkeys) {
                        let lastOffset;
                        for (let i = 0; i < node.leafkeys.length; i += 1) {
                            const { key } = node.leafkeys[i];
                            if (name.localeCompare(key) < 0 && lastOffset) {
                                return bptReadNode(lastOffset);
                            }
                            lastOffset = node.leafkeys[i].offset;
                        }
                        return bptReadNode(lastOffset);
                    }
                    for (let i = 0; i < node.keys.length; i += 1) {
                        if (node.keys[i].key === name) {
                            return Object.assign(Object.assign({}, node.keys[i]), { field });
                        }
                    }
                    return undefined;
                });
                const rootNodeOffset = 32;
                return bptReadNode(Number(offset) + rootNodeOffset);
            }));
            return filterUndef(yield Promise.all(locs));
        });
    }
    /*
     * retrieve the features from the bigbed data that were found through the lookup of the extraIndex
     * note that there can be multiple extraIndex, see the BigBed specification and the -extraIndex argument to bedToBigBed
     *
     * @param name - the name to search for
     * @param opts - a SearchOptions argument with optional signal
     * @return a Promise for an array of Feature
     */
    searchExtraIndex(name, opts = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const blocks = yield this.searchExtraIndexBlocks(name, opts);
            if (!blocks.length) {
                return [];
            }
            const view = yield this.getUnzoomedView(opts);
            const res = blocks.map(block => {
                return new rxjs_1.Observable(observer => {
                    view.readFeatures(observer, [block], opts);
                }).pipe((0, operators_1.reduce)((acc, curr) => acc.concat(curr)), (0, operators_1.map)(x => {
                    for (let i = 0; i < x.length; i += 1) {
                        x[i].field = block.field;
                    }
                    return x;
                }));
            });
            const ret = yield (0, rxjs_1.firstValueFrom)((0, rxjs_1.merge)(...res));
            return ret.filter(f => { var _a; return ((_a = f.rest) === null || _a === void 0 ? void 0 : _a.split('\t')[(f.field || 0) - 3]) === name; });
        });
    }
}
exports.BigBed = BigBed;
//# sourceMappingURL=bigbed.js.map